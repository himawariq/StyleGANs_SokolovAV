from __future__ import annotations
from rudalle.pipelines import generate_images, show, super_resolution, cherry_pick_by_clip
from rudalle import get_rudalle_model, get_tokenizer, get_vae, get_realesrgan, get_ruclip
from rudalle.utils import seed_everything
from PIL import Image
import random
import argparse
import functools
import os
import pickle
import sys
import numpy as np
import torch
import torch.nn as nn
import streamlit as st



st.set_page_config(
     page_title="SokolovAVapp",
     page_icon="üßä",
     layout="wide",
     initial_sidebar_state="expanded")

def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser()
    parser.add_argument('--device', type=str, default='cpu')
    parser.add_argument('--theme', type=str)
    parser.add_argument('--live', action='store_true')
    parser.add_argument('--share', action='store_true')
    parser.add_argument('--port', type=int)
    parser.add_argument('--disable-queue',
                        dest='enable_queue',
                        action='store_false')
    parser.add_argument('--allow-flagging', type=str, default='never')
    parser.add_argument('--allow-screenshot', action='store_true')
    return parser.parse_args()


def generate_z(z_dim: int, seed: int, device: torch.device) -> torch.Tensor:
    return torch.from_numpy(np.random.RandomState(seed).randn(
        1, z_dim)).to(device).float()


@torch.inference_mode()
def generate_image(seed: int, truncation_psi: float, model: nn.Module,
                   device: torch.device) -> np.ndarray:
    seed = int(np.clip(seed, 0, np.iinfo(np.uint32).max))

    z = generate_z(model.z_dim, seed, device)
    label = torch.zeros([1, model.c_dim], device=device)

    out = model(z, label, truncation_psi=truncation_psi, force_fp32=True)
    out = (out.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)
    return out[0].cpu().numpy()
def generate_interpolated_images(
        seed0: int, psi0: float, seed1: int, psi1: float,
        num_intermediate: int, model: nn.Module,
        device: torch.device) -> tuple[list[np.ndarray], np.ndarray]:
    seed0 = int(np.clip(seed0, 0, np.iinfo(np.uint32).max))
    seed1 = int(np.clip(seed1, 0, np.iinfo(np.uint32).max))

    z0 = generate_z(model.z_dim, seed0, device)
    z1 = generate_z(model.z_dim, seed1, device)
    vec = z1 - z0
    dvec = vec / (num_intermediate + 1)
    zs = [z0 + dvec * i for i in range(num_intermediate + 2)]
    dpsi = (psi1 - psi0) / (num_intermediate + 1)
    psis = [psi0 + dpsi * i for i in range(num_intermediate + 2)]

    label = torch.zeros([1, model.c_dim], device=device)

    res = []
    for z, psi in zip(zs, psis):
        out = model(z, label, truncation_psi=psi, force_fp32=True)
        out = (out.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(
            torch.uint8)
        out = out[0].cpu().numpy()
        res.append(out)
    concatenated = np.hstack(res)
    return res, concatenated


def load_model(file_name: str, device: torch.device) -> nn.Module:
    path = 'models/stylegan_human_v2_1024.pkl'
    with open(path, 'rb') as f:
        model = pickle.load(f)['G_ema']
    model.eval()
    model.to(device)
    with torch.inference_mode():
        z = torch.zeros((1, model.z_dim)).to(device)
        label = torch.zeros([1, model.c_dim], device=device)
        model(z, label, force_fp32=True)
    return model

def load_model1(file_name: str, device: torch.device) -> nn.Module:
    path = './models/network-snapshot-000560.pkl'
    with open(path, 'rb') as f:
        model = pickle.load(f)['G_ema']
    model.eval()
    model.to(device)
    with torch.inference_mode():
        z = torch.zeros((1, model.z_dim)).to(device)
        label = torch.zeros([1, model.c_dim], device=device)
        model(z, label, force_fp32=True)
    return model



def main():

    st.title('')
    menu = ['–û –ü—Ä–æ–µ–∫—Ç–µ','–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å [1] –ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ', '–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ –º–∞–Ω–∏–ø—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ [1] —Å—Ç–∏–ª–µ–º','–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å [2] –ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ',
            '–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ –º–∞–Ω–∏–ø—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ [2] —Å—Ç–∏–ª–µ–º','–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞']
    choice = st.sidebar.selectbox('–ú–µ–Ω—é', menu)

    if choice == '–û –ü—Ä–æ–µ–∫—Ç–µ':
        st.markdown("<h1 style='text-align: center; color: black; font-size: 32px;'>–ú–∞–≥–∏—Å—Ç–µ—Ä—Å–∫–∞—è –¥–∏—Å—Å–µ—Ä—Ç–∞—Ü–∏—è –Ω–∞ —Ç–µ–º—É <br> ¬´–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ StyleGANs –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö –≤ e-commerce¬ª</h1>", unsafe_allow_html = True)

        st.success(
            '''–ê–≤—Ç–æ—Ä –¥–∞–Ω–Ω–æ–≥–æ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è: **–°–æ–∫–æ–ª–æ–≤ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –í–ª–∞–¥–∏—Å–ª–∞–≤–æ–≤–∏—á, –í–®–≠**  \n –ù–∞—É—á–Ω—ã–π —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å: **–ü—Ä–æ—Å–≤–µ—Ç–æ–≤ –ê—Ä—Ç–µ–º –í–ª–∞–¥–∏–º–∏—Ä–æ–≤–∏—á, –ö–∞–Ω–¥–∏–¥–∞—Ç —Ñ–∏–∑–∏–∫–æ-–º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –Ω–∞—É–∫,  \n –†—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å –ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –≤ –†–∞–π–¥—Ç–µ—Ö, –Ø–Ω–¥–µ–∫—Å**''')
        col1, col2, col3 = st.columns(3)

        with col1:
            st.image("https://media.giphy.com/media/h2mwamAvxIXXYKRXty/giphy.gif")

        with col2:
            st.image("https://media.giphy.com/media/wcRQGfE7rR5MzqOauo/giphy.gif")

        with col3:
            st.image("https://media.giphy.com/media/crTs54iF2E8dFTfSdN/giphy.gif")
        col4, col5, col6 = st.columns(3)

        with col4:
            st.image("https://media.giphy.com/media/GUSLVKr1fCNJUwgW2q/giphy.gif")

        with col5:
            st.image("https://media.giphy.com/media/eyehti0n6xxxIuMvIz/giphy.gif")

        with col6:
            st.image("https://media.giphy.com/media/rwPlpxsORgEf5tRiIU/giphy.gif")

        st.markdown(''' –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–Ω–ª–∞–π–Ω-–ø—Ä–∏–º–µ—Ä–æ—á–Ω–æ–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞—Å—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–∞—è 1024x512 –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ 40k –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –º–æ–¥–µ–ª–µ–π, –∞ —Ç–∞–∫–∂–µ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –≤ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–∏ 512—Ö512–Ω–∞ –æ—Å–Ω–æ–≤–µ StyleGAN2-ada-pytorch –Ω–∞ –¥–∞–Ω–Ω—ã—Ö DeepFashion.  \n **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≤ –¥–∞–ª—å—à–µ–π–Ω–µ–º –±—É–¥—É—Ç —É–ª—É—á—à–∞—Ç—å—Å—è –∏ –ø—Ä–∏–º–µ–Ω—è—Ç—å—Å—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –æ–ø—ã—Ç–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤!**''')
        st.markdown('''**–ß—Ç–æ –º–æ–∂–Ω–æ –∏ –Ω—É–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å**:  \n  
        1. –í –∫–∞—á–µ—Å—Ç–≤–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –º–æ–¥–µ–ª–µ–π, –∞ —Ç–∞–∫–∂–µ –æ–Ω–ª–∞–π–Ω-–ø—Ä–∏–º–µ—Ä–æ—á–Ω—É—é –≤ AR-—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö.  
    2. –ú–æ–∂–Ω–æ –∏–∑–≤–ª–µ–∫–∞—Ç—å —Å—É—â–Ω–æ—Å—Ç–∏ –∏–∑ –≤—Ö–æ–¥—è—â–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø–æ–º–æ—â—å—é SMPL-X –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è 3D –º–æ–¥–µ–ª–∏ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ —Ç–µ–ª–∞ 
       –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –µ–≥–æ —Å—Ç–∏–ª—è. 
    3. –í –¥–∞–Ω–Ω–æ–º –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –º–µ—Ç–æ–¥ FaceInput, —á—Ç–æ–±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –≤—ã–±—Ä–∞—Ç—å  –≤—Ö–æ–¥—è—â–µ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ª–∏—Ü–∞ –∏ –≤—Å—Ç–∞–≤–∏—Ç—å –µ–≥–æ 
       –≤ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–π —Å—Ç–∏–ª—å –º–æ–¥–µ–ª–∏. –ó–∞–≥–≤–æ–∑–¥–∫–∞ –≤ —Ç–æ–º, —á—Ç–æ –Ω–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç FaceInput –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ª–∏—Ü–∞ –∏–∑ 
       –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–≥–æ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞, –ø–æ—ç—Ç–æ–º—É –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –Ω—É–∂–Ω–æ –±—ã–ª–æ –±—ã –º–µ–Ω—è—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏ —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Ñ–æ—Ä–º–∞—Ç, 
       –Ω–∞ –∫–æ—Ç–æ—Ä—ã–π –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –¥–∞–Ω–Ω–∞—è –¥–∏–ø–ª–æ–º–Ω–∞—è —Ä–∞–±–æ—Ç–∞ –Ω–µ –±—ã–ª–∞ –Ω–∞—Ü–µ–ª–µ–Ω–∞''')



    if choice == '–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å [1] –ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ':
        st.subheader('–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ [1] –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞')
        args = parse_args()
        device = torch.device(args.device)

        model = load_model('stylegan_human_v2_1024.pkl', device)

        func = functools.partial(generate_image, model=model, device=device)
        func = functools.update_wrapper(func, generate_image)
        with st.form(key='123'):
            with st.sidebar:
                seed = st.number_input(min_value=0, label='–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –∏–∑ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞')
                psi = st.slider(min_value=0.0, max_value=2.0, step=0.05, value=0.7, label='–£—Å–µ—á–µ–Ω–Ω–æ–µ –ø—Å–∏')
                test1 = func(seed,psi)
                submit_text = st.form_submit_button(label='–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å!')
        st.image(test1, width=600)

    if choice == '–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ –º–∞–Ω–∏–ø—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ [1] —Å—Ç–∏–ª–µ–º':
        st.subheader('–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ –º–∞–Ω–∏–ø—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ [1] —Å—Ç–∏–ª–µ–º')
        args = parse_args()
        device = torch.device(args.device)

        model = load_model('models/stylegan_human_v2_1024.pkl', device)
        func = functools.partial(generate_interpolated_images,
                                 model=model,
                                 device=device)
        func = functools.update_wrapper(func, generate_interpolated_images)
        with st.form(key='123'):
            with st.sidebar:
                seed = st.number_input(min_value=0, label='–í—ã–±–æ—Ä [1] –º–æ–¥–µ–ª–∏ –∏–∑ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞', key=0)
                psi = st.slider(min_value=0.0, max_value=2.0, step=0.05, value=0.7, label='–£—Å–µ—á–µ–Ω–Ω–æ–µ –ø—Å–∏', key=0)

                seed1 = st.number_input(min_value=0, label='–í—ã–±–æ—Ä [2] –º–æ–¥–µ–ª–∏ –∏–∑ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞', key=1)
                psi1 = st.slider(min_value=0.0, max_value=2.0, step=0.05, value=0.7, label='–£—Å–µ—á–µ–Ω–Ω–æ–µ –ø—Å–∏', key=1)
                slid = st.slider(min_value=0, max_value=21, step=1, value=7, label='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π')
                test11 = func(seed, psi, seed1, psi1, slid)
                submit_text = st.form_submit_button(label='–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å!')
        st.image(test11[1], width=650)
        st.image(test11[0], width=600)




    if choice == '–ò—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å [2] –ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ':
        st.subheader('–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ [2] –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞')
        args = parse_args()
        device = torch.device(args.device)

        model = load_model1('models/network-snapshot-000560.pkl', device)

        func = functools.partial(generate_image, model=model, device=device)
        func = functools.update_wrapper(func, generate_image)
        with st.form(key='123'):
            with st.sidebar:
                seed = st.number_input(min_value=0, label='–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –∏–∑ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞')
                psi = st.slider(min_value=0.0, max_value=2.0, step=0.05, value=0.7, label='–£—Å–µ—á–µ–Ω–Ω–æ–µ –ø—Å–∏')
                test1 = func(seed,psi)
                submit_text = st.form_submit_button(label='–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å!')
        st.image(test1, width=600)

    if choice == '–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ –º–∞–Ω–∏–ø—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ [2] —Å—Ç–∏–ª–µ–º':
        st.subheader('–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∏ –º–∞–Ω–∏–ø—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ [2] —Å—Ç–∏–ª–µ–º')
        args = parse_args()
        device = torch.device(args.device)

        model = load_model1('models/network-snapshot-000560.pkl', device)
        func = functools.partial(generate_interpolated_images,
                                 model=model,
                                 device=device)
        func = functools.update_wrapper(func, generate_interpolated_images)
        with st.form(key='123'):
            with st.sidebar:
                seed = st.number_input(min_value=0, label='–í—ã–±–æ—Ä [1] –º–æ–¥–µ–ª–∏ –∏–∑ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞', key=0)
                psi = st.slider(min_value=0.0, max_value=2.0, step=0.05, value=0.7, label='–£—Å–µ—á–µ–Ω–Ω–æ–µ –ø—Å–∏', key=0)

                seed1 = st.number_input(min_value=0, label='–í—ã–±–æ—Ä [2] –º–æ–¥–µ–ª–∏ –∏–∑ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞', key=1)
                psi1 = st.slider(min_value=0.0, max_value=2.0, step=0.05, value=0.7, label='–£—Å–µ—á–µ–Ω–Ω–æ–µ –ø—Å–∏', key=1)
                slid = st.slider(min_value=0, max_value=21, step=1, value=7, label='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π')
                test11 = func(seed, psi, seed1, psi1, slid)
                submit_text = st.form_submit_button(label='–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å!')
        st.image(test11[1], width=650)
        st.image(test11[0], width=600)




    if choice == '–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞':
        st.subheader('–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ tuned –º–æ–¥–µ–ª–∏ ruDALL-E –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –æ–ø–∏—Å–∞–Ω–∏—é')
        device = 'cuda'
        dalle = get_rudalle_model("Malevich", pretrained=True, fp16=True, device=device)
        tokenizer = get_tokenizer()
        vae = get_vae().to(device)

        def dalle_wrapper(prompt: str):
            pil_images = []

            top_k, top_p = random.choice([
                (1024, 0.98),
                (512, 0.97),
                (384, 0.96),

            ])

            _images, _ = generate_images(
                prompt,
                tokenizer,
                dalle,
                vae,
                top_k=top_k,
                images_num=2,
                top_p=top_p
            )
            pil_images += _images

            return pil_images

        with st.form(key='123'):
            raw_text = st.text_input('–í–≤–µ–¥–∏—Ç–µ —á—Ç–æ-–Ω–∏–±—É–¥—å')
            submit_text = st.form_submit_button(label='–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ!')
            if submit_text!='':
                st.image(dalle_wrapper(raw_text), width=600)



if __name__ == '__main__':
    main()
